{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDXsvnuMG9ypYU3WJQ84sf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkiru-ede/nkiru_codes/blob/master/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RB7ONzb4Y-E5"
      },
      "outputs": [],
      "source": [
        "#Installing important packages\n",
        "pip install twython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "id": "cq_-bBdRZF18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "z0nC2WN-ZH18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "qGHMdgHnZJ-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing important libraries\n",
        "import pandas as pd\n",
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "from datetime import date\n",
        "from datetime import time\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "import matplotlib.font_manager\n",
        "from itertools import cycle, islice\n",
        "import numpy as np\n",
        "import tweepy\n",
        "import requests\n",
        "import base64\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import corpus\n",
        "from geopy.geocoders import Nominatim\n",
        "import numpy as np\n",
        "import gmplot\n",
        "import webbrowser\n",
        "from twython import Twython\n",
        "import json\n",
        "from twython import Twython\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.ticker as ticker"
      ],
      "metadata": {
        "id": "BVfSpGuPZL3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Twitter credentials into Json format\n",
        "credentials={}\n",
        "credentials['CONSUMER_KEY'] = 'k45uvcP2VAYtiMcv5WPZmf6wC'\n",
        "credentials['CONSUMER_SECRET'] = 'g2KxMpvOBj5ebQpExDVFAuYHrkTU99ICAcdNBprbTHieS6US0n'\n",
        "credentials['ACCESS_TOKEN'] = '3102441035-Wdz2E2JPzu9Piom64ZAQ9rJZ3JbOYNkEHJAwM2C'\n",
        "credentials['ACCESS_SECRET'] = 'GyFKlqD6hgfjZGsN6j3YMq3peEcPw96I0FyrM5Mfvqn1y'\n",
        "\n",
        "with open(\"twitter_credentials.json\", \"w\") as file:\n",
        "    json.dump(credentials, file)"
      ],
      "metadata": {
        "id": "_AwQnTrKZOty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Streaming data for sentiment analysis\n",
        "\n",
        "from twython import TwythonStreamer\n",
        "import csv\n",
        "import json\n",
        "\n",
        "with open('twitter_credentials.json','r') as file:\n",
        "    creds = json.load(file)\n",
        "\n",
        "def process_tweet(tweet):\n",
        "    d = {}\n",
        "    d['hashtags'] = [hashtag['text'] for hashtag in tweet['entities']['hashtags']]\n",
        "    d['text'] = tweet['text']\n",
        "    d['user_screenName'] = tweet['user']['screen_name']\n",
        "    d['user_name'] = tweet['user']['name']\n",
        "    d['user_loc'] = tweet['user']['location']\n",
        "    d['source'] = tweet['source']\n",
        "    d['verified'] = tweet['user']['verified']\n",
        "    d['created_at'] = tweet['created_at']\n",
        "    d['followers'] = tweet['user']['followers_count']\n",
        "    d['retweet'] = tweet['retweet_count']\n",
        "    d['coordinates'] = tweet['coordinates']\n",
        "    return d\n",
        "\n",
        "#Create class that inherits TwythonStreamer\n",
        "class MyStreamer(TwythonStreamer):\n",
        "    #recieved data\n",
        "    def on_success(self,data):\n",
        "        if data['lang'] == 'en':\n",
        "            tweet_data = process_tweet(data)\n",
        "            self.save_to_csv(tweet_data)\n",
        "            \n",
        "    def on_error(self,status_code, data):\n",
        "        print(status_code, data)\n",
        "        self.disconnect()\n",
        "        \n",
        "    def save_to_csv(self,tweet):\n",
        "        with open (r'NeilParish.csv','a', encoding = 'utf-8') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow(list(tweet.values()))\n",
        "#load credentials\n",
        "stream = MyStreamer(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'], creds['ACCESS_TOKEN'], creds['ACCESS_SECRET'])\n",
        "stream.statuses.filter(track='Neil Parish')\n"
      ],
      "metadata": {
        "id": "VanrUoqPZWHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add column headers to dataframe\n",
        "df = pd.read_csv(\"NeilParish.csv\",\n",
        "                  names=[\"hashtags\", \"text\", \"user_screenName\", \"user_name\",\"user_loc\", \"source\", \"verified\", \"created_at\", \"followers\", \"retweet\", \"coordinates\"])\n",
        "#print new dataframe\n",
        "df"
      ],
      "metadata": {
        "id": "0ezhn0ycZYpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract only tweet text from dataframe\n",
        "tweet =  df.text\n",
        "df = pd.DataFrame(tweet)"
      ],
      "metadata": {
        "id": "9q_g8XiOZm0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean text - sentiment analysis\n",
        "def cleantext(text):\n",
        "  text = re.sub(r'@[A-Za-z0-9]+', '', text) #removes @mentions\n",
        "  text = re.sub(r'#','', text) # removes #\n",
        "  text = re.sub(r'RT[\\s]+', '', text)#removes RT\n",
        "  text = re.sub(r'https?:/\\/\\S+', '', text)#removes hhtp\n",
        "  return text\n",
        "df['text'] = df['text'].apply(cleantext)\n",
        "#print new dataframe\n",
        "df"
      ],
      "metadata": {
        "id": "cS6VNFI9ZsZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a function to get the subjectivity\n",
        "#subjectivity - tells how subjective the text/opinion is\n",
        "def getSubjectivity(text):\n",
        "    return TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "#Create a function to get the polarity\n",
        "#polarity tells how positive or negative a text is\n",
        "def getPolarity(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        " \n",
        "#create two new columns\n",
        "df['Subjectivity'] = df['text'].apply(getSubjectivity)\n",
        "df['Polarity'] = df['text'].apply(getPolarity)\n",
        "\n",
        "#show the new dataframe\n",
        "df"
      ],
      "metadata": {
        "id": "SWhJI_MVZvk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a function to compute the negative, neautral and positive analysis\n",
        "def getAnalysis(score):\n",
        "  if score < 0:\n",
        "    return 'Negative'\n",
        "  elif score == 0:\n",
        "    return 'Neutral'\n",
        "  else:\n",
        "    return 'Positive'\n",
        "df['Analysis'] = df['Polarity'].apply(getAnalysis)\n",
        "df"
      ],
      "metadata": {
        "id": "tUtR7p80Z0BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print the negative tweets\n",
        "j=1\n",
        "sortedDF = df.sort_values(by=['Polarity'], ascending = 'False')\n",
        "for i in range(0, sortedDF.shape[0]):\n",
        "  if (sortedDF['Analysis'][i] == 'Negative'):\n",
        "    print(str(j)+')'+sortedDF['text'][i])\n",
        "    print()\n",
        "    j=j+1"
      ],
      "metadata": {
        "id": "CMgiK-d0Z23D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print the positive tweets\n",
        "j=1\n",
        "sortedDF = df.sort_values(by=['Polarity'], ascending = 'False')\n",
        "for i in range(0, sortedDF.shape[0]):\n",
        "  if (sortedDF['Analysis'][i] == 'Positive'):\n",
        "    print(str(j)+')'+sortedDF['text'][i])\n",
        "    print()\n",
        "    j=j+1"
      ],
      "metadata": {
        "id": "-FvXlbFQZ9bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print the neutral tweets\n",
        "j=1\n",
        "sortedDF = df.sort_values(by=['Polarity'], ascending = 'False')\n",
        "for i in range(0, sortedDF.shape[0]):\n",
        "  if (sortedDF['Analysis'][i] == 'Neutral'):\n",
        "    print(str(j)+')'+sortedDF['text'][i])\n",
        "    print()\n",
        "    j=j+1"
      ],
      "metadata": {
        "id": "a0AwvSvpaAE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#put the different sentiments in seperate dataframes\n",
        "Positive = df[df['Analysis']== \"Positive\"]\n",
        "Negative = df[df['Analysis']== \"Negative\"]\n",
        "Neutral = df[df['Analysis']== \"Neutral\"]"
      ],
      "metadata": {
        "id": "5LixJp01aC3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to visualise dataframe - WordCloud and Frequency Distribution\n",
        "def visualiser(data):\n",
        "    fdist = nltk.FreqDist()\n",
        "    en_stop = set(stopwords.words('english'))\n",
        "    for i in data[\"text\"]:\n",
        "      i = re.sub(r\"[^a-zA-Z0-9]+\",\" \", i)\n",
        "      i = nltk.word_tokenize(i)\n",
        "      stopped_tokens = [t for t in i if not t in en_stop]\n",
        "      for j in stopped_tokens:\n",
        "        fdist[j] +=1\n",
        "    fdist.plot(30, cumulative=False)\n",
        "    \n",
        "    wordcloud = WordCloud(max_font_size=50, max_words = 100, background_color=\"white\").generate_from_frequencies(fdist)\n",
        "    plt.figure()\n",
        "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "8mAFbTAqaKXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualise positive sentiment tweets\n",
        "visualiser(Positive)"
      ],
      "metadata": {
        "id": "dtYN_YZQaR3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualise negative sentiment tweets\n",
        "visualiser(Negative)"
      ],
      "metadata": {
        "id": "jcfNLO-badYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualise neutral sentiment tweets\n",
        "visualiser(Neutral)"
      ],
      "metadata": {
        "id": "M_tRZwVjajmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scatter plot the different sentiments\n",
        "sns.set(style=\"darkgrid\")    \n",
        "fig, ax = plt.subplots(figsize=(8, 5))    \n",
        "palette = sns.color_palette(\"bright\", 3)\n",
        "g = sns.scatterplot(ax=ax, x=\"Polarity\", y=\"Subjectivity\", hue=\"Analysis\", marker='o', data=df, s=100, palette= palette)\n",
        "g.legend(bbox_to_anchor=(1, 1), ncol=1)\n",
        "#g.set(xlim = (50000,250000))"
      ],
      "metadata": {
        "id": "5BPHLUM9ara0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the percentage of positive tweets\n",
        "ptweets = df[df.Analysis=='Positive']\n",
        "ptweets = ptweets['text']\n",
        "ptweets\n",
        "round( (ptweets.shape[0] /df.shape[0]) * 100 , 1)"
      ],
      "metadata": {
        "id": "8gcsIQ7ha20r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the percentage of negative tweets\n",
        "ntweets = df[df.Analysis=='Negative']\n",
        "ntweets = ntweets['text']\n",
        "ntweets\n",
        "round( (ntweets.shape[0] /df.shape[0]) * 100 , 1)"
      ],
      "metadata": {
        "id": "Xoywc6cma_Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the percentage of neutral tweets\n",
        "nntweets = df[df.Analysis=='Neutral']\n",
        "nntweets = nntweets['text']\n",
        "nntweets\n",
        "round( (nntweets.shape[0] /df.shape[0]) * 100 , 1)"
      ],
      "metadata": {
        "id": "Tj8jvK0va3pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show the value count\n",
        "df['Analysis'].value_counts()\n",
        "#plot and visualize the counts\n",
        "plt.title('Sentiment Analysis')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Counts')\n",
        "df['Analysis'].value_counts().plot(kind='bar', color = list('gcrymc'))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MluWzbZRa55D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}